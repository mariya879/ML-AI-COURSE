{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f140a33-b7f2-4fc8-a923-5c8fc1331009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b68caa7-c6e2-4ddb-9e5d-761b00f838b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>7916</td>\n",
       "      <td>0</td>\n",
       "      <td>Live out loud #lol #liveoutloud #selfie #smile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>7917</td>\n",
       "      <td>0</td>\n",
       "      <td>We would like to wish you an amazing day! Make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>Helping my lovely 90 year old neighbor with he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>7919</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally got my #smart #pocket #wifi stay conne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple Barcelona!!! #Apple #Store #BCN #Barcelo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet\n",
       "0        1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1        2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2        3      0  We love this! Would you go? #talk #makememorie...\n",
       "3        4      0  I'm wired I know I'm George I was made that wa...\n",
       "4        5      1  What amazing service! Apple won't even talk to...\n",
       "...    ...    ...                                                ...\n",
       "7915  7916      0  Live out loud #lol #liveoutloud #selfie #smile...\n",
       "7916  7917      0  We would like to wish you an amazing day! Make...\n",
       "7917  7918      0  Helping my lovely 90 year old neighbor with he...\n",
       "7918  7919      0  Finally got my #smart #pocket #wifi stay conne...\n",
       "7919  7920      0  Apple Barcelona!!! #Apple #Store #BCN #Barcelo...\n",
       "\n",
       "[7920 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48e53da0-140a-47aa-8005-981f445c6683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c22c5b8-7c72-4dbe-85c5-bd755c20c3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: click in /home/intern1/.local/lib/python3.8/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/intern1/.local/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.5.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/intern1/.local/lib/python3.8/site-packages (from nltk) (4.66.4)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.2/776.2 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2024.5.15\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb117c7-0c7e-46f7-8f49-bcf3095f6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "618b0044-282c-4afd-afe1-ae6bcc52587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "009661c3-f6a2-413f-aa45-bd4b6171e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba8b349b-cf57-470c-934d-58350fedb27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa6a5c24-8c7a-4b3a-86b0-6916bd4038d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_tweet'] = df['tweet'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c617ff-82c0-4cb2-a050-4c9db9ecddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/intern1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/intern1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and stopwords removal\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aac8022-48f3-4211-a7df-33c3940071b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "652affb2-675d-4086-a265-331760ef7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_tweet'] = df['processed_tweet'].apply(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1b051d0-f9f0-4517-9c1d-31a83a6674d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [fingerprint, pregnancy, test, android, apps, ...\n",
       "1       [finally, transparant, silicon, case, thanks, ...\n",
       "2       [love, would, go, talk, makememories, unplug, ...\n",
       "3       [im, wired, know, im, george, made, way, iphon...\n",
       "4       [amazing, service, apple, wont, even, talk, qu...\n",
       "                              ...                        \n",
       "7915    [live, loud, lol, liveoutloud, selfie, smile, ...\n",
       "7916    [would, like, wish, amazing, day, make, every,...\n",
       "7917    [helping, lovely, 90, year, old, neighbor, ipa...\n",
       "7918    [finally, got, smart, pocket, wifi, stay, conn...\n",
       "7919    [apple, barcelona, apple, store, bcn, barcelon...\n",
       "Name: processed_tweet, Length: 7920, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88b17c82-6ab2-4878-a969-6a78d1d36373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['processed_tweet'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96c11654-89ed-40ed-9a60-8e21030a9329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization (using TF-IDF)\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
    "X_train_tfidf = tfidf.fit_transform(X_train.apply(lambda x: ' '.join(x)))\n",
    "X_test_tfidf = tfidf.transform(X_test.apply(lambda x: ' '.join(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf234e22-5d9c-44a0-b685-1686add5fe83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8fe3b5d-3e09-48ab-94d5-7b36a2de4d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/intern1/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/intern1/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1152\n",
      "           1       0.86      0.65      0.74       432\n",
      "\n",
      "    accuracy                           0.87      1584\n",
      "   macro avg       0.87      0.80      0.83      1584\n",
      "weighted avg       0.87      0.87      0.87      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Vectorization (using TF-IDF)\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
    "X_train_tfidf = tfidf.fit_transform(X_train.apply(lambda x: ' '.join(x)))\n",
    "X_test_tfidf = tfidf.transform(X_test.apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Model training (using Logistic Regression as an example)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Classification report (optional)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55a660-8cef-42d1-819b-83f196a58911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
